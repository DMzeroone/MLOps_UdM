# üöï NYC Taxi Duration Prediction - Gu√≠a de Despliegue

Esta gu√≠a te ayudar√° a desplegar el servicio de predicci√≥n de duraci√≥n de viajes de taxi de NYC paso a paso.

## üìã Tabla de Contenidos

- [Prerequisitos](#prerequisitos)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Instalaci√≥n](#instalaci√≥n)
- [Configuraci√≥n del Entorno](#configuraci√≥n-del-entorno)
- [Despliegue Local](#despliegue-local)
- [Pruebas del Servicio](#pruebas-del-servicio)
- [Monitoreo](#monitoreo)
- [Troubleshooting](#troubleshooting)
- [Despliegue en Producci√≥n](#despliegue-en-producci√≥n)

## üîß Prerequisitos

Antes de comenzar, aseg√∫rate de tener instalado:

- **Python 3.8+**
- **uv** (gestor de paquetes y entornos virtuales moderno)
- **Git** (para clonar el repositorio)
- **curl** (para probar los endpoints)

### Verificar Instalaciones

```bash
# Verificar Python
python --version
# o
python3 --version

# Verificar uv
uv --version

# Verificar Git
git --version

# Verificar curl
curl --version
```

### Instalar uv (si no lo tienes)

```bash
# En macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# En Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Con pip (alternativa)
pip install uv
```

## üìÅ Estructura del Proyecto

```
04-Deployment/deploy/web-service/
‚îú‚îÄ‚îÄ README.md              # Esta gu√≠a
‚îú‚îÄ‚îÄ pyproject.toml         # Configuraci√≥n uv y dependencias
‚îú‚îÄ‚îÄ .python-version        # Versi√≥n de Python del proyecto
‚îú‚îÄ‚îÄ predict.py             # Servicio Flask principal
‚îú‚îÄ‚îÄ predict_test.py        # M√≥dulo de testing sin servidor
‚îú‚îÄ‚îÄ test.py               # Cliente de pruebas HTTP
‚îú‚îÄ‚îÄ lin_reg.bin           # Modelo entrenado (pickle)
‚îú‚îÄ‚îÄ main.py               # Punto de entrada alternativo
‚îî‚îÄ‚îÄ .venv/                # Entorno virtual (creado autom√°ticamente)
```

## üöÄ Instalaci√≥n

### Paso 1: Navegar al Directorio del Proyecto

```bash
# Navegar al directorio web-service
cd /Users/mdurango/University/MLOps/04-Deployment/deploy/web-service/
```

### Paso 2: El Entorno ya est√° Configurado

El proyecto ya tiene configurado un entorno uv independiente con:
- **pyproject.toml** - Configuraci√≥n del proyecto y dependencias
- **Entorno virtual** - Se crea autom√°ticamente al ejecutar comandos
- **Dependencias instaladas** - Flask, scikit-learn, pandas, numpy, requests, gunicorn

### Paso 3: Verificar la Configuraci√≥n

```bash
# Verificar que uv detecta el proyecto
uv info

# Ver dependencias instaladas
uv tree
```

### Instalar Dependencias Adicionales (si es necesario)

```bash
# Agregar nuevas dependencias
uv add <package-name>

# Instalar dependencias de desarrollo
uv add --dev pytest black flake8

# Instalar para producci√≥n
uv add gunicorn
```

### Ejecutar Comandos en el Entorno

```bash
# Ejecutar cualquier comando Python con uv
uv run python predict.py

# Ejecutar scripts directamente
uv run python test.py

# Ver informaci√≥n del proyecto
uv info
```

## ‚öôÔ∏è Configuraci√≥n del Entorno

### Verificar el Proyecto uv

```bash
# Ver informaci√≥n del proyecto
uv info

# Ver dependencias instaladas
uv tree

# Ver archivos del proyecto
ls -la
```

### Verificar el Modelo

Aseg√∫rate de que el archivo `lin_reg.bin` est√© presente:

```bash
# Verificar que el modelo existe
ls -la lin_reg.bin

# Si el archivo existe, deber√≠as ver algo como:
# -rw-r--r-- 1 user user 411363 fecha lin_reg.bin
```

### Probar la Carga del Modelo

```bash
# Ejecutar prueba directa del modelo
uv run python predict_test.py
```

**Salida esperada:**

```
INFO:__main__:üîÑ Loading model and DictVectorizer for testing...
INFO:__main__:‚úÖ Model and DV loaded successfully
INFO:__main__:üß™ Running prediction test...
INFO:__main__:‚úÖ Features prepared for testing: PU_DO=161_236, distance=2.5
INFO:__main__:üéØ Testing prediction made: 12.34 minutes
INFO:__main__:üìä Test result:
INFO:__main__:   Origin: 161
INFO:__main__:   Destination: 236
INFO:__main__:   Distance: 2.5 miles
INFO:__main__:   Predicted duration: 12.34 minutes
```

## üåê Despliegue Local

### M√©todo 1: Ejecutar el Servidor Flask

```bash
# Ejecutar el servidor principal
uv run python predict.py
```

**Salida esperada:**

```
INFO:__main__:üîÑ Loading model and DictVectorizer...
INFO:__main__:‚úÖ Model and DV loaded successfully
INFO:__main__:üöÄ Starting Flask server on port 9696...
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:9696
 * Running on http://[tu-ip]:9696
```

### M√©todo 2: Usando Flask CLI

```bash
# Configurar variables de entorno
export FLASK_APP=predict.py
export FLASK_ENV=development

# Ejecutar servidor
flask run --host=0.0.0.0 --port=9696
```

### M√©todo 3: Usando Gunicorn (Producci√≥n)

```bash
# Instalar Gunicorn
uv add gunicorn

# Ejecutar con Gunicorn
uv run gunicorn --bind 0.0.0.0:9696 --workers 4 predict:app
```

## üß™ Pruebas del Servicio

### Prueba 1: Health Check

```bash
# Verificar que el servicio est√° funcionando
curl http://localhost:9696/health
```

**Respuesta esperada:**

```json
{
  "dv_loaded": true,
  "model_loaded": true,
  "service": "NYC Taxi Duration Prediction",
  "status": "healthy"
}
```

### Prueba 2: Predicci√≥n Simple

```bash
# Hacer una predicci√≥n
curl -X POST http://localhost:9696/predict \
  -H "Content-Type: application/json" \
  -d '{
    "PULocationID": 161,
    "DOLocationID": 236,
    "trip_distance": 2.5
  }'
```

**Respuesta esperada:**

```json
{
  "duration": 12.34,
  "pickup_location": 161,
  "dropoff_location": 236,
  "trip_distance": 2.5
}
```

### Prueba 3: Suite Completa de Pruebas

```bash
# Ejecutar cliente de pruebas automatizado
uv run python test.py
```

**Salida esperada:**

```
INFO:__main__:üöÄ Starting test client for NYC Taxi API...
INFO:__main__:üß™ Starting comprehensive test suite...

INFO:__main__:1Ô∏è‚É£ Testing Health Check...
INFO:__main__:üè• Checking health endpoint at http://localhost:9696/health
INFO:__main__:‚úÖ Service healthy!

INFO:__main__:2Ô∏è‚É£ Testing basic prediction...
INFO:__main__:üöï Sending test request to http://localhost:9696/predict
INFO:__main__:‚úÖ Request successful!
INFO:__main__:üìà Predicted duration: 12.34 minutes

INFO:__main__:3Ô∏è‚É£ Testing edge cases...
INFO:__main__:   üîç Case: Short trip
INFO:__main__:   ‚úÖ Short trip: 8.45 minutes
INFO:__main__:   üîç Case: Long trip
INFO:__main__:   ‚úÖ Long trip: 45.67 minutes

INFO:__main__:üéâ Test suite completed!
```

## üìä Monitoreo

### Logs del Servidor

Los logs aparecer√°n en la consola donde ejecutaste el servidor:

```
INFO:__main__:üöï New prediction: 161 -> 236
INFO:__main__:‚úÖ Features prepared: PU_DO=161_236, distance=2.5
INFO:__main__:üéØ Prediction made: 12.34 minutes
INFO:__main__:‚úÖ Response sent: 12.34 minutes
```

### Endpoints Disponibles


| Endpoint   | M√©todo | Descripci√≥n                  |
| ---------- | ------- | ----------------------------- |
| `/health`  | GET     | Verificar estado del servicio |
| `/predict` | POST    | Realizar predicci√≥n          |

### Formato de Request para `/predict`

```json
{
  "PULocationID": 161,      // ID de zona de recogida (1-263)
  "DOLocationID": 236,      // ID de zona de destino (1-263)
  "trip_distance": 2.5      // Distancia en millas
}
```

### Formato de Response

```json
{
  "duration": 12.34,        // Duraci√≥n predicha en minutos
  "pickup_location": 161,   // Zona de recogida
  "dropoff_location": 236,  // Zona de destino
  "trip_distance": 2.5      // Distancia del viaje
}
```

## üîß Troubleshooting

### Problema 1: "lin_reg.bin file not found"

**S√≠ntomas:**

```
ERROR:__main__:‚ùå Error: lin_reg.bin file not found
```

**Soluci√≥n:**

```bash
# Verificar que el archivo existe en el directorio correcto
ls -la lin_reg.bin

# Si no existe, necesitas entrenar el modelo primero
# o copiar el archivo desde otro directorio
```

### Problema 2: "Port already in use"

**S√≠ntomas:**

```
OSError: [Errno 48] Address already in use
```

**Soluci√≥n:**

```bash
# Encontrar el proceso usando el puerto 9696
lsof -i :9696

# Terminar el proceso
kill -9 <PID>

# O usar un puerto diferente
python predict.py --port 9697
```

### Problema 3: Errores de Dependencias

**S√≠ntomas:**

```
ModuleNotFoundError: No module named 'flask'
```

**Soluci√≥n:**

```bash
# Verificar que el entorno virtual est√° activado
which python

# Reinstalar dependencias
pip install -r requirements.txt
```

### Problema 4: Errores de Predicci√≥n

**S√≠ntomas:**

```json
{
  "error": "Missing required field: PULocationID"
}
```

**Soluci√≥n:**

- Verificar que el JSON incluye todos los campos requeridos
- Verificar el Content-Type header: `application/json`
- Verificar que los valores son del tipo correcto (int/float)

## üöÄ Despliegue en Producci√≥n

### Opci√≥n 1: Docker

```bash
# Crear Dockerfile
cat > Dockerfile << EOF
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 9696

CMD ["gunicorn", "--bind", "0.0.0.0:9696", "--workers", "4", "predict:app"]
EOF

# Construir imagen
docker build -t taxi-prediction .

# Ejecutar contenedor
docker run -p 9696:9696 taxi-prediction
```

### Opci√≥n 2: Heroku

```bash
# Crear Procfile
echo "web: gunicorn predict:app" > Procfile

# Crear runtime.txt
echo "python-3.9.16" > runtime.txt

# Deploy a Heroku
heroku create tu-app-name
git add .
git commit -m "Deploy taxi prediction service"
git push heroku main
```

### Opci√≥n 3: AWS EC2

```bash
# En tu instancia EC2
sudo apt update
sudo apt install python3-pip
pip3 install -r requirements.txt

# Usar systemd para mantener el servicio corriendo
sudo nano /etc/systemd/system/taxi-prediction.service
```

### Variables de Entorno para Producci√≥n

```bash
# Configurar variables de entorno
export FLASK_ENV=production
export MODEL_PATH=/path/to/lin_reg.bin
export PORT=9696
export WORKERS=4
```

## üìö Recursos Adicionales

### Comandos √ötiles

```bash
# Ver procesos de Python
ps aux | grep python

# Monitorear logs en tiempo real
tail -f /var/log/taxi-prediction.log

# Verificar uso de memoria
htop

# Hacer m√∫ltiples requests de prueba
for i in {1..10}; do curl -X POST http://localhost:9696/predict -H "Content-Type: application/json" -d '{"PULocationID": 161, "DOLocationID": 236, "trip_distance": 2.5}'; done
```

### Mejores Pr√°cticas

1. **Siempre usar entornos virtuales**
2. **Validar datos de entrada**
3. **Implementar logging adecuado**
4. **Usar HTTPS en producci√≥n**
5. **Implementar rate limiting**
6. **Monitorear m√©tricas de performance**

### Pr√≥ximos Pasos

* Implementar autenticaci√≥n (capas de seguridad)
* Generar board con m√©tricas del sistema (cantidad de instancias, responses, memoria, tiempos de respuesta) - [DataDog](https://docs.datadoghq.com/es/getting_started/application/)

* Agregar tests unitarios

* Configurar CI/CD pipeline

## üÜò Soporte

Si tienes problemas:

1. **Revisa los logs** del servidor
2. **Verifica las dependencias** est√°n instaladas
3. **Confirma que el modelo** se carga correctamente
4. **Prueba con curl** antes de usar clientes complejos
5. **Consulta la documentaci√≥n** de Flask si es necesario

**¬°Felicidades! üéâ Tu servicio de predicci√≥n de taxi est√° listo para usar.**

Para m√°s informaci√≥n sobre MLOps y despliegue de modelos, consulta la documentaci√≥n de teo y yo hemos preparado para ti.
