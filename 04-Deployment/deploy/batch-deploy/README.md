# üöÄ NYC Taxi Batch Prediction System

Sistema enterprise-grade de predicciones por lotes para duraci√≥n de viajes de taxis NYC usando **Prefect** para orquestaci√≥n y scheduling autom√°tico.

## üéØ ¬øQu√© es Batch Deployment?

El **batch deployment** procesa grandes vol√∫menes de datos de manera programada, a diferencia del web service que responde en tiempo real. Es ideal para:

- **Procesamiento masivo**: Miles de predicciones simult√°neas
- **Ejecuci√≥n programada**: Autom√°tico cada X horas/d√≠as
- **Recursos optimizados**: Uso eficiente de CPU/memoria
- **An√°lisis hist√≥rico**: Procesar datos acumulados

## üèóÔ∏è Arquitectura del Sistema

```mermaid
graph TD
    A[Data Generator] --> B[Input Data]
    B --> C[Prefect Orchestrator]
    C --> D[Batch Predictor]
    D --> E[Output Results]
    C --> F[Monitoring & Logs]
    C --> G[Cleanup Tasks]
    
    H[Scheduler] --> C
    I[Prefect UI] --> C
```

### üîÑ Flujo Completo

1. **Generaci√≥n de Datos**: Simula viajes realistas de taxis NYC
2. **Validaci√≥n**: Verifica calidad y formato de datos
3. **Procesamiento**: Predicciones ML en paralelo
4. **Almacenamiento**: Guarda resultados organizadamente
5. **Limpieza**: Mantiene el sistema optimizado

### üéØ Caracter√≠sticas Principales

- **üîÑ Scheduling Autom√°tico**: Cada 2 horas via Prefect
- **‚ö° Procesamiento Paralelo**: Multi-threading configurable
- **üìä Generaci√≥n de Datos**: Simulaci√≥n realista de viajes NYC
- **üßπ Auto Cleanup**: Gesti√≥n autom√°tica de archivos antiguos
- **üìà Monitoreo**: M√©tricas de sistema y performance
- **üîí Gesti√≥n de Recursos**: L√≠mites de CPU/Memory
- **üìÅ Almacenamiento Organizado**: Input/Output/Processed

## üöÄ Gu√≠a Completa de Deployment

### **Paso 1: Setup Autom√°tico (Recomendado)**

```bash
# Ejecutar script de configuraci√≥n completa
./scripts/setup_batch_system.sh
```

**¬øQu√© hace este script?**
- ‚úÖ Verifica Python y UV
- ‚úÖ Instala dependencias
- ‚úÖ Copia modelo ML
- ‚úÖ Crea estructura de directorios
- ‚úÖ Configura variables de entorno
- ‚úÖ Ejecuta tests de validaci√≥n

### **Paso 2: Setup Manual (Alternativo)**

```bash
# 1. Instalar dependencias
uv sync

# 2. Copiar modelo desde web-service
cp ../web-service/lin_reg.bin .

# 3. Crear estructura de directorios
mkdir -p data/{input,output,processed} logs config

# 4. Crear archivo de configuraci√≥n
cp .env.example .env  # Editar seg√∫n necesidades
```

## üéÆ Formas de Ejecutar el Sistema

### **Opci√≥n A: Producci√≥n con Prefect Server (Recomendado)**

**Terminal 1: Iniciar Servidor Prefect**
```bash
uv run prefect server start --host 0.0.0.0 --port 4200
```

**Terminal 2: Configurar API y Crear Deployments**
```bash
# Configurar URL de API
export PREFECT_API_URL=http://0.0.0.0:4200/api

# Crear deployments autom√°ticos
uv run python scripts/deploy_prefect.py
```

**Terminal 3: Iniciar Worker**
```bash
# Iniciar worker para ejecutar flows
uv run prefect worker start --pool default-agent-pool
```

**Acceder a la UI**: [http://localhost:4200](http://localhost:4200)

### **Opci√≥n B: Modo Desarrollo (Local)**

```bash
# Servir flows localmente sin servidor
uv run python scripts/deploy_prefect.py serve
```

### **Opci√≥n C: Ejecuci√≥n Manual (Testing)**

```bash
# 1. Generar datos de prueba
uv run python src/data_generator.py

# 2. Ejecutar predicci√≥n por lotes
uv run python src/batch_predictor.py

# 3. Probar flow completo
export PREFECT_API_URL=http://0.0.0.0:4200/api
uv run python -c "
from src.prefect_flows import taxi_batch_prediction_flow
result = taxi_batch_prediction_flow(batch_id='test_manual', use_parallel=False)
print(f'‚úÖ Procesadas {result[\"processing_stats\"][\"num_predictions\"]} predicciones')
"
```

## üìã Deployments de Prefect Creados

| Deployment | Horario | Descripci√≥n | Comando Manual |
|------------|---------|-------------|----------------|
| `taxi-batch-prediction-scheduled` | Cada 2 horas | Procesamiento autom√°tico | `prefect deployment run taxi-batch-prediction-scheduled` |
| `taxi-batch-cleanup-scheduled` | Diario 2 AM | Limpieza y mantenimiento | `prefect deployment run taxi-batch-cleanup-scheduled` |
| `taxi-batch-prediction-manual` | Bajo demanda | Ejecuci√≥n manual | `prefect deployment run taxi-batch-prediction-manual` |

## üîß Configuraci√≥n del Sistema

### **Variables de Entorno** (`.env`)

```bash
# Configuraci√≥n de Procesamiento
BATCH_SIZE=1000              # Tama√±o de lote para procesamiento
MAX_WORKERS=4                # N√∫mero de workers paralelos
NUM_TRIPS_PER_BATCH=5000     # Viajes por lote generado
CHUNK_SIZE=100               # Tama√±o de chunk para paralelizaci√≥n

# Configuraci√≥n de Scheduling (formato cron)
BATCH_SCHEDULE_CRON="0 */2 * * *"    # Cada 2 horas
CLEANUP_SCHEDULE_CRON="0 2 * * *"    # Diario a las 2 AM

# Configuraci√≥n de Prefect
PREFECT_API_URL=http://0.0.0.0:4200/api
PREFECT_WORK_POOL=default-agent-pool

# Retenci√≥n de Archivos (d√≠as)
OUTPUT_RETENTION_DAYS=30     # Mantener outputs 30 d√≠as
LOG_RETENTION_DAYS=7         # Mantener logs 7 d√≠as

# L√≠mites de Recursos
MEMORY_LIMIT_GB=4.0          # L√≠mite de memoria
CPU_LIMIT_PERCENT=80.0       # L√≠mite de CPU

# Monitoreo
ENABLE_METRICS=true
METRICS_PORT=8000
LOG_LEVEL=INFO
```

### **Configuraciones Clave** (`config/settings.py`)

- **BATCH_SIZE**: N√∫mero de predicciones por chunk de procesamiento
- **MAX_WORKERS**: Hilos de procesamiento paralelo (ajustar seg√∫n CPU)
- **NUM_TRIPS_PER_BATCH**: Cantidad de viajes simulados por lote
- **RETENTION_DAYS**: Pol√≠ticas de limpieza autom√°tica
- **RESOURCE_LIMITS**: Umbrales de CPU/Memory para alertas

## üìä Flujo de Datos Detallado

### **1. Inputs: Datos de Entrada**

**Formato de Input** (Parquet):
```json
{
    "trip_id": "trip_20250118_143022_000001",
    "batch_timestamp": "2025-01-18T14:30:22",
    "PULocationID": 161,
    "DOLocationID": 236, 
    "trip_distance": 2.5,
    "pickup_datetime": "2025-01-18T14:30:22"
}
```

**Caracter√≠sticas de los Datos**:
- **PULocationID**: ID de zona de pickup (1-263)
- **DOLocationID**: ID de zona de dropoff (1-263)
- **trip_distance**: Distancia en millas (0.1-50.0)
- **Sesgo Manhattan**: 70% viajes en Manhattan, 30% otros boroughs
- **Distribuci√≥n realista**: Log-normal para distancias

### **2. Procesamiento: Pipeline ML**

**Feature Engineering**:
```python
# Combinaci√≥n pickup-dropoff
features['PU_DO'] = f"{PULocationID}_{DOLocationID}"
features['trip_distance'] = trip_distance
```

**Procesamiento Paralelo**:
- **Chunking**: Divide dataset en chunks de 100-1000 registros
- **Multi-threading**: 2-8 workers seg√∫n CPU disponible
- **DictVectorizer**: Transforma features categ√≥ricas
- **LinearRegression**: Modelo pre-entrenado para predicci√≥n

### **3. Outputs: Resultados**

**Formato de Output** (Parquet):
```json
{
    "trip_id": "trip_20250118_143022_000001",
    "predicted_duration": 12.34,
    "prediction_timestamp": "2025-01-18T14:35:45",
    "pickup_location": 161,
    "dropoff_location": 236,
    "trip_distance": 2.5,
    "batch_timestamp": "2025-01-18T14:30:22"
}
```

**Ubicaci√≥n de Archivos**:
- **Input**: `data/input/taxi_batch_YYYYMMDD_HHMMSS.parquet`
- **Output**: `data/output/predictions_BATCH_ID_YYYYMMDD_HHMMSS.parquet`
- **Processed**: `data/processed/processed_BATCH_ID_*.parquet`

**M√©tricas de Output**:
- **Throughput**: ~2000+ predicciones/segundo
- **Tama√±o archivo**: ~1-5 MB por lote (5000 viajes)
- **Formato**: Parquet comprimido para eficiencia

## üìÅ Directory Structure

```
batch-deploy/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_generator.py      # Data simulation
‚îÇ   ‚îú‚îÄ‚îÄ batch_predictor.py     # ML prediction engine
‚îÇ   ‚îî‚îÄ‚îÄ prefect_flows.py       # Prefect orchestration
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_batch_system.sh  # Automated setup
‚îÇ   ‚îî‚îÄ‚îÄ deploy_prefect.py      # Deployment management
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py            # Configuration management
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/                 # Raw batch files
‚îÇ   ‚îú‚îÄ‚îÄ output/                # Prediction results
‚îÇ   ‚îî‚îÄ‚îÄ processed/             # Processed files
‚îú‚îÄ‚îÄ logs/                      # Application logs
‚îú‚îÄ‚îÄ pyproject.toml             # Dependencies
‚îî‚îÄ‚îÄ lin_reg.bin               # ML model
```

## üéØ Prefect Flow Details

### **Main Flow: `taxi_batch_prediction_flow`**
1. **System Check**: Validate resources (CPU/Memory)
2. **Data Generation**: Create realistic taxi trip data
3. **Data Validation**: Ensure data quality and format
4. **Batch Processing**: Parallel ML predictions
5. **Output Management**: Save results with metadata
6. **File Management**: Move processed files

### **Cleanup Flow: `taxi_batch_cleanup_flow`**
1. **Resource Check**: Monitor system health
2. **File Cleanup**: Remove old files based on retention policy
3. **Space Management**: Free up disk space

## üìà Performance y Monitoreo

### **M√©tricas T√≠picas de Performance**

- **Throughput**: ~2000+ predicciones/segundo
- **Uso de Memoria**: ~2-4 GB para 5000 viajes
- **Tiempo de Procesamiento**: ~3-5 segundos por lote
- **Tama√±o de Archivo**: ~1-5 MB por lote (Parquet)
- **Paralelizaci√≥n**: 2-8 workers seg√∫n CPU disponible

### **Comandos de Monitoreo**

```bash
# Verificar recursos del sistema
uv run python -c "
from src.batch_predictor import BatchPredictor
p = BatchPredictor()
print('üìä M√©tricas del Sistema:')
metrics = p.get_system_metrics()
for key, value in metrics.items():
    print(f'  {key}: {value}')
"

# Ver logs en tiempo real
tail -f logs/batch_prediction.log

# Verificar archivos generados
ls -la data/output/ | head -10
```

### **Prefect UI - Monitoreo Visual**

- **Dashboard**: [http://localhost:4200](http://localhost:4200)
- **Flow Runs**: Historial de ejecuciones
- **Task Status**: Estado de cada tarea
- **Logs Detallados**: Logs de cada step
- **M√©tricas**: Performance y recursos

## üÜò Troubleshooting

### **Common Issues**

#### **Error: "Model file not found"**
```bash
# Copy model from web-service
cp ../web-service/lin_reg.bin .
```

#### **Error: "Prefect server not running"**
```bash
# Start Prefect server
uv run prefect server start --host 0.0.0.0 --port 4200
```

#### **Error: "No worker available"**
```bash
# Start a worker
uv run prefect worker start --pool default-agent-pool
```

#### **Error: "High memory usage"**
```bash
# Reduce batch size in .env
BATCH_SIZE=500
MAX_WORKERS=2
```

### **Performance Tuning**

#### **For Large Datasets (>10K trips)**
```bash
# Increase parallel processing
MAX_WORKERS=8
CHUNK_SIZE=200
```

#### **For Limited Resources**
```bash
# Conservative settings
MAX_WORKERS=2
BATCH_SIZE=500
CHUNK_SIZE=50
```

## üîç Monitoring & Observability

### **Prefect UI Features**
- **Flow Runs**: Track execution history
- **Task Status**: Monitor individual task progress
- **Logs**: Detailed execution logs
- **Metrics**: Performance and resource usage
- **Alerts**: Failure notifications

### **Log Locations**
- **Application Logs**: `logs/`
- **Prefect Logs**: Prefect UI
- **System Metrics**: Built-in monitoring

## üöÄ Production Deployment

### **Recommended Setup**
1. **Dedicated Server**: 4+ CPU cores, 8+ GB RAM
2. **Persistent Storage**: For data and logs
3. **Monitoring**: Prefect Cloud or self-hosted UI
4. **Backup Strategy**: Regular model and data backups
5. **Alerting**: Email/Slack notifications for failures

### **Scaling Considerations**
- **Horizontal**: Multiple workers across machines
- **Vertical**: Increase `MAX_WORKERS` and `BATCH_SIZE`
- **Storage**: Use cloud storage for large datasets
- **Database**: PostgreSQL for Prefect metadata

## üìö Advanced Usage

### **Custom Scheduling**
```python
# Custom cron schedule
BATCH_SCHEDULE_CRON="0 8,12,16,20 * * *"  # 4 times daily
```

### **External Data Sources**
```python
# Modify data_generator.py to read from:
# - Database (PostgreSQL, MySQL)
# - API endpoints
# - Cloud storage (S3, GCS)
# - Message queues (Kafka, RabbitMQ)
```

### **Model Updates**
```bash
# Replace model file
cp new_model.bin lin_reg.bin

# Restart flows to pick up new model
uv run prefect deployment run taxi-batch-prediction-manual
```

## üéì Learning Objectives

After completing this exercise, you should understand:

- ‚úÖ **Batch Processing Patterns**: Chunking, parallel processing
- ‚úÖ **Workflow Orchestration**: Prefect flows, tasks, deployments
- ‚úÖ **Production MLOps**: Scheduling, monitoring, maintenance
- ‚úÖ **Resource Management**: CPU/Memory optimization
- ‚úÖ **Data Pipeline Design**: Input ‚Üí Processing ‚Üí Output
- ‚úÖ **Error Handling**: Retries, validation, cleanup
- ‚úÖ **Observability**: Logging, metrics, monitoring

## üìû Support

If you encounter issues:

1. **Check Logs**: Review application and Prefect logs
2. **Verify Setup**: Run `./scripts/setup_batch_system.sh`
3. **Test Components**: Run individual modules
4. **Resource Check**: Monitor CPU/Memory usage
5. **Ask for Help**: Provide specific error messages

---

**üéâ Happy Batch Processing!** This system demonstrates enterprise-grade MLOps practices with automated scheduling, monitoring, and maintenance.
